{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVp0qeJL_nSm"
      },
      "source": [
        "# Traffic Forecasting with Pytorch Geometric Temporal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaEHCakD_s7q"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svWjrrJxjp8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc85334-d630-47b0-d6e2-ec199f1ac7fa"
      },
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "pt_version = torch.__version__\n",
        "print(pt_version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "824V69yXsSub"
      },
      "source": [
        "time consuming step .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjWHdw_Dj3KQ"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2nTO8PH_vlf"
      },
      "source": [
        "## Dataset\n",
        "- Traffic forecasting dataset based on Los Angeles Metropolitan traffic\n",
        "- 207 loop detectors on highways\n",
        "- March 2012 - June 2012\n",
        "- From the paper: Diffusion Convolutional Recurrent Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOc-jbFckFHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "aab9a9f3-82e3-4cb6-aea3-b766a3c8b28f"
      },
      "source": [
        "import numpy as np\n",
        "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "\n",
        "loader = METRLADatasetLoader()\n",
        "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
        "\n",
        "print(\"Dataset type:  \", dataset)\n",
        "print(\"Number of samples / sequences: \",  len(set(dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2zO_CjYBQSt"
      },
      "source": [
        "#### Data Sample\n",
        "- 207 nodes\n",
        "- 2 features per node (speed, time)\n",
        "- 12 timesteps per bucket (12 x 5 min = 60 min)\n",
        "- Labels for 12 future timesteps (normalized speed) --> node regression\n",
        "- Edge_attr is build based on the distances between sensors + threshold\n",
        "- Further details: https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/dataset/metr_la.html#METRLADatasetLoader\n",
        "- Raw data: https://graphmining.ai/temporal_datasets/METR-LA.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClWnMrz0Anjr"
      },
      "source": [
        "# Show first sample\n",
        "next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL3fnTZyQIQz"
      },
      "source": [
        "# Important: It is not always like that!\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "d = ChickenpoxDatasetLoader().get_dataset(lags=4)\n",
        "next(iter(d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df8yjwxoA69S"
      },
      "source": [
        ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrkqXPxFwIx"
      },
      "source": [
        "import seaborn as sns\n",
        "# Visualize traffic over time\n",
        "sensor_number = 1\n",
        "hours = 24\n",
        "sensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\n",
        "sns.lineplot(data=sensor_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZqDAqQdBS8Q"
      },
      "source": [
        "#### Test Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMn2LXERsyVK"
      },
      "source": [
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
        "\n",
        "print(\"Number of train buckets: \", len(set(train_dataset)))\n",
        "print(\"Number of test buckets: \", len(set(test_dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1puzm8U_xpY"
      },
      "source": [
        "## Model\n",
        "\n",
        "\n",
        "- A3TGCN is an extension of TGCN that uses attention\n",
        "- The spatial aggregation uses GCN, the temporal aggregation a GRU\n",
        "- We can pass in periods to get an embedding for several timesteps\n",
        "- This embedding can be used to predict several steps into the future = output dimension\n",
        "- We could also do this in a loop and feed it again into the model (would be autoregressive)\n",
        "- There is only one block here. Other layers also allow stacking???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQB8MPV0sU4K"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
        "\n",
        "class TemporalGNN(torch.nn.Module):\n",
        "    def __init__(self, node_features, periods):\n",
        "        super(TemporalGNN, self).__init__()\n",
        "        # Attention Temporal Graph Convolutional Cell\n",
        "        self.tgnn = A3TGCN(in_channels=node_features,\n",
        "                           out_channels=32,\n",
        "                           periods=periods)\n",
        "        # Equals single-shot prediction\n",
        "        self.linear = torch.nn.Linear(32, periods)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        x = Node features for T time steps\n",
        "        edge_index = Graph edge indices\n",
        "        \"\"\"\n",
        "        h = self.tgnn(x, edge_index)\n",
        "        h = F.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h\n",
        "\n",
        "TemporalGNN(node_features=2, periods=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDbNmvO2_znb"
      },
      "source": [
        "## Training\n",
        "\n",
        "- Training on GPU didn't bring much speed-up\n",
        "- I ran into RAM issues, why I only train on a smaller subset of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kOvaOrps2oe"
      },
      "source": [
        "# GPU support\n",
        "device = torch.device('cpu') # cuda\n",
        "subset = 2000\n",
        "\n",
        "# Create model and optimizers\n",
        "model = TemporalGNN(node_features=2, periods=12).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "print(\"Running training...\")\n",
        "for epoch in range(10):\n",
        "    loss = 0\n",
        "    step = 0\n",
        "    for snapshot in train_dataset:\n",
        "        snapshot = snapshot.to(device)\n",
        "        # Get model predictions\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index)\n",
        "        # Mean squared error\n",
        "        loss = loss + torch.mean((y_hat-snapshot.y)**2)\n",
        "        step += 1\n",
        "        if step > subset:\n",
        "          break\n",
        "\n",
        "    loss = loss / (step + 1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X18pWbNsPSjb"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "- Lets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\n",
        "- The model always gets one hour and needs to predict the next hour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNERp-_xs27y"
      },
      "source": [
        "model.eval()\n",
        "loss = 0\n",
        "step = 0\n",
        "horizon = 288\n",
        "\n",
        "# Store for analysis\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for snapshot in test_dataset:\n",
        "    snapshot = snapshot.to(device)\n",
        "    # Get predictions\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index)\n",
        "    # Mean squared error\n",
        "    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n",
        "    # Store for analysis below\n",
        "    labels.append(snapshot.y)\n",
        "    predictions.append(y_hat)\n",
        "    step += 1\n",
        "    if step > horizon:\n",
        "          break\n",
        "\n",
        "loss = loss / (step+1)\n",
        "loss = loss.item()\n",
        "print(\"Test MSE: {:.4f}\".format(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIVZyX1b_IPA"
      },
      "source": [
        "### Visualization\n",
        "\n",
        "- The further away the point in time is, the worse the predictions get\n",
        "- Predictions shape: [num_data_points, num_sensors, num_timesteps]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5AJPBdRMb4b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sensor = 123\n",
        "timestep = 11\n",
        "preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in predictions])\n",
        "labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\n",
        "print(\"Data points:,\", preds.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08wwv2qUR7z9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,5))\n",
        "sns.lineplot(data=preds, label=\"pred\")\n",
        "sns.lineplot(data=labs, label=\"true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3GC5nmwSde0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
